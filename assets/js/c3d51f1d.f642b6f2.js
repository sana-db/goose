"use strict";(self.webpackChunkgoose=self.webpackChunkgoose||[]).push([[2446],{34603:(e,o,t)=>{t.r(o),t.d(o,{assets:()=>r,contentTitle:()=>i,default:()=>d,frontMatter:()=>l,metadata:()=>n,toc:()=>c});var n=t(99981),a=t(74848),s=t(28453);const l={title:"Goose and Qwen3 for local execution",description:"Qwen3 and tool calling with goose, an example local workflow",authors:["mic"]},i="Local workflows and local agents",r={authorsImageUrls:[void 0]},c=[{value:"advanced tips",id:"advanced-tips",level:2}];function h(e){const o={a:"a",code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",...(0,s.R)(),...e.components},{Head:t}=o;return t||function(e,o){throw new Error("Expected "+(o?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Head",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(o.p,{children:["A couple of weeks back Qwen 3 (",(0,a.jsx)(o.a,{href:"https://qwenlm.github.io/blog/qwen3/",children:"https://qwenlm.github.io/blog/qwen3/"}),") launched with a raft of capabilities and sizes."]}),"\n",(0,a.jsx)(o.p,{children:"This model showed promise and even in very compact form, such as 8B parameters and 4bit quantisation, was able to do tool calling successfully with goose.\nEven multi turn tool calling."}),"\n",(0,a.jsx)(o.p,{children:"I haven't seen this work at such a scaled down model so far, so this is really impressive and bodes well for both this model, but also future open weight models both large and small.\nI would expect the Qwen3 larger models work quite well on various tasks but even this small one I found useful."}),"\n",(0,a.jsxs)(o.p,{children:["For some time I have had a little helper function in my ",(0,a.jsx)(o.code,{children:"~/.zshrc"})," file for command line usage:"]}),"\n",(0,a.jsx)(o.pre,{children:(0,a.jsx)(o.code,{className:"language-zsh",children:'# zsh helper to use goose if you make a typo or just want to yolo into the shell\ncommand_not_found_handler() {\n  local cmd="$*"\n  echo "\ud83e\udebf:"\n  goose run -t "can you try to run this command please: $cmd"\n}\n'})}),"\n",(0,a.jsxs)(o.p,{children:["This makes use of a zsh feature (zsh now being standard on macos) that will delegate to that function if nothing else on the command line makes sense.\nThis lets me either make typos or just type in what I want in the command line such as ",(0,a.jsx)(o.code,{children:"$> can you kill whatever is listening on port 8000"})," and goose will do the work, don't even need to open a goose session."]}),"\n",(0,a.jsx)(o.p,{children:"With Qwen3 + ollama running all locally with goose, it worked well enough I switched over to a complete local version of that workflow:"}),"\n",(0,a.jsx)(o.pre,{children:(0,a.jsx)(o.code,{className:"language-zsh",children:'command_not_found_handler() {\n  local cmd="$*"\n  echo "\ud83e\udebf:"\n  GOOSE_PROVIDER=ollama GOOSE_MODEL=michaelneale/qwen3 goose run -t "can you try to run this command please: $cmd"\n}\n'})}),"\n",(0,a.jsx)(o.p,{children:"which works when I am offline, on the train etc."}),"\n",(0,a.jsx)(o.h1,{id:"qwen3-reasoning",children:"Qwen3 reasoning"}),"\n",(0,a.jsxs)(o.p,{children:['By default Qwen 3 models will "think" (reason) about the problem, as they are general purpose models, but I found it was quicker (and worked better for my purpose) to make it go into this reason stage.\nBy adding ',(0,a.jsx)(o.code,{children:"/no_think"})," to the system prompt, it will general skip to the execution (this may make it less successful at larger tasks but this is a small model for just a few turns of tool calls in this case)."]}),"\n",(0,a.jsxs)(o.p,{children:["I made a small tweak to the default Ollama chat template here: ",(0,a.jsx)(o.a,{href:"https://ollama.com/michaelneale/qwen3",children:"https://ollama.com/michaelneale/qwen3"})," which you can use as above that you can use as above, if you like (or the default ",(0,a.jsx)(o.code,{children:"qwen3"})," model hosted by ollama also works fine out of the box)"]}),"\n",(0,a.jsx)(o.h2,{id:"advanced-tips",children:"advanced tips"}),"\n",(0,a.jsxs)(o.p,{children:["You can use the goose ",(0,a.jsx)(o.code,{children:"/plan"})," mode with a seperate model (perhaps Qwen3 with reasoning, or another model such as deepseek) to help plan actions before shifting to Qwen3 for the execution (via tool calls)."]}),"\n",(0,a.jsx)(o.p,{children:'It would be interesting to try the larger models if, you have access to hardware (I have only used the 8B parameter one).\nMy current setup is a 64G M1 pro macbook (circa 2022 hardware) which has probably less than 48G available to use for GPUs/AI, which puts a limit on what I can run, but qwen3 with "no think" mode works acceptably for my purposes.'}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("meta",{property:"og:title",content:"Goose and Qwen3 for local execution"}),(0,a.jsx)("meta",{property:"og:type",content:"article"}),(0,a.jsx)("meta",{property:"og:url",content:"https://block.github.io/goose/blog/2025/05/12/local-goose-qwen3"}),(0,a.jsx)("meta",{property:"og:description",content:"Qwen3 and tool calling with goose, an example local workflow"}),(0,a.jsx)("meta",{name:"twitter:card",content:"summary_large_image"}),(0,a.jsx)("meta",{property:"twitter:domain",content:"block.github.io/goose"}),(0,a.jsx)("meta",{name:"twitter:title",content:"Goose and Qwen3 for local execution"}),(0,a.jsx)("meta",{name:"twitter:description",content:"Qwen3 and tool calling with goose, an example local workflow"})]})]})}function d(e={}){const{wrapper:o}={...(0,s.R)(),...e.components};return o?(0,a.jsx)(o,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},28453:(e,o,t)=>{t.d(o,{R:()=>l,x:()=>i});var n=t(96540);const a={},s=n.createContext(a);function l(e){const o=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(o):{...o,...e}}),[o,e])}function i(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:l(e.components),n.createElement(s.Provider,{value:o},e.children)}},99981:e=>{e.exports=JSON.parse('{"permalink":"/goose/blog/2025/05/12/local-goose-qwen3","source":"@site/blog/2025-05-12-local-goose-qwen3/index.md","title":"Goose and Qwen3 for local execution","description":"Qwen3 and tool calling with goose, an example local workflow","date":"2025-05-12T00:00:00.000Z","tags":[],"readingTime":2.92,"hasTruncateMarker":false,"authors":[{"name":"Michael Neale","title":"Principal Engineer","page":{"permalink":"/goose/blog/authors/mic"},"socials":{"github":"https://github.com/michaelneale"},"imageURL":"https://avatars.githubusercontent.com/u/14976?v=4","key":"mic"}],"frontMatter":{"title":"Goose and Qwen3 for local execution","description":"Qwen3 and tool calling with goose, an example local workflow","authors":["mic"]},"unlisted":false,"nextItem":{"title":"Championship Driven Development: Your Team\'s AI Playbook for Peak Performance","permalink":"/goose/blog/2025/05/09/developers-ai-playbook-for-team-efficiency"}}')}}]);